plugins {
    id("java")
    id("kotlin").version("1.2.50")
    id("application")
    id("com.github.johnrengelman.shadow").version("2.0.1")
    id("org.junit.platform.gradle.plugin").version("1.0.0")
}

ext {
    kotlinVersion = "1.2.50"
    hadoopVersion = "3.1.0"

    libraryPath = "${project.rootDir}/lib"
    hadoopLibraryPath = System.getenv("HADOOP_HOME") ?: "${libraryPath}/hadoop/hadoop-$hadoopVersion/bin"
    hdfViewLibraryPath = "${libraryPath}/hdf/hdf-view/lib"
    hdfJavaLibraryPath = "${libraryPath}/hdf/hdf-java/lib/libjhdf5.so"
    // hdfLibraryPath = "$hdfJavaLibraryPath:$hdfViewLibraryPath"
    hdfLibraryPath = hdfJavaLibraryPath

    analysisInputPath = "${project.rootDir}/data/songs/B"
    analysisOutputPath = "${project.rootDir}/out/analytics"
}

repositories {
    mavenCentral()
    maven {
        url = "http://dl.bintray.com/jetbrains/spek"
    }
}

dependencies {
    compile(fileTree(hdfJavaLibraryPath))
    compile(fileTree(hdfViewLibraryPath))
    compile("org.jetbrains.kotlin:kotlin-stdlib-jdk8:$kotlinVersion")
    compile("org.apache.hadoop:hadoop-common:$hadoopVersion")
    compile("org.apache.hadoop:hadoop-mapreduce-client-core:$hadoopVersion")
    testCompile("junit:junit:4.12")
    testCompile("org.jetbrains.kotlin:kotlin-reflect:$kotlinVersion")
    testCompile("org.jetbrains.spek:spek-api:1.1.5") {
        exclude("group": "org.jetbrains.kotlin")
    }
    testRuntime("org.jetbrains.spek:spek-junit-platform-engine:1.1.5") {
        exclude("group": "org.jetbrains.kotlin")
    }
}

configurations {
    compile.exclude("group": "org.slf4j")
    compile.exclude("group": "log4j")
}

group = "de.unihalle.informatik.bigdata.millionsongdataset"
version = "0.1.0"
mainClassName = "de.unihalle.informatik.bigdata.millionsongdataset.analysis.Analyse"

sourceCompatibility = 1.8

compileKotlin {
    kotlinOptions {
        jvmTarget = "1.8"
    }
}

compileTestKotlin {
    kotlinOptions {
        jvmTarget = "1.8"
    }
}

task "runAnalyse" ("type": Exec, "dependsOn": ["cleanRunAnalyse", "shadowJar"]) {
    doFirst {
        file(analysisOutputPath).deleteDir()
    }

    commandLine "export HADOOP_ROOT_LOGGER=\"WARN,console\""

    commandLine "$hadoopLibraryPath/hadoop",
            "fs", "-copyFromLocal",
            hdfLibraryPath, hdfLibraryPath

    commandLine "$hadoopLibraryPath/hadoop",
            "jar", shadowJar.archivePath.path,
            "-Dmapreduce.map.java.opts=-Dhdf.hdf5lib.H5.hdf5lib=$hdfLibraryPath",
            "-Dmapreduce.reduce.java.opts=-Dhdf.hdf5lib.H5.hdf5lib=$hdfLibraryPath",
            "-Dmapreduce.map.java.opts=-Xmx2048m",
            "-Dmapreduce.reduce.java.opts=-Xmx2048m",
            "-Dhdf.hdf5lib.H5.hdf5lib=$hdfLibraryPath",
            "-Dhadoop.root.logger=WARN,DRFA",
            analysisInputPath,
            analysisOutputPath

    outputs.dir(analysisOutputPath)
    outputs.upToDateWhen { false }
}


task "runPrintSongData" ("type": JavaExec, "dependsOn": "testClasses") {
    main = "de.unihalle.informatik.bigdata.millionsongdataset.analysis.PrintSongData"
    classpath = sourceSets.test.runtimeClasspath

    // Pass the HDF5 native library path to all Java tasks
    systemProperty("hdf.hdf5lib.H5.hdf5lib", hdfLibraryPath)
}

task "runTestSongData" ("type": JavaExec, "dependsOn": "testClasses") {
    main = "de.unihalle.informatik.bigdata.millionsongdataset.analysis.TestSongData"
    classpath = sourceSets.test.runtimeClasspath

    // Pass the HDF5 native library path to all Java tasks
    systemProperty("hdf.hdf5lib.H5.hdf5lib", hdfLibraryPath)
}

task "runTestInputFormat" ("type": JavaExec, "dependsOn": "testClasses") {
    main = "de.unihalle.informatik.bigdata.millionsongdataset.analysis.TestInputFormat"
    classpath = sourceSets.test.runtimeClasspath

    // Pass the HDF5 native library path to all Java tasks
    systemProperty("hdf.hdf5lib.H5.hdf5lib", hdfLibraryPath)
}

test {
    // Pass the HDF5 native library path to all Java tasks
    systemProperty("hdf.hdf5lib.H5.hdf5lib", hdfLibraryPath)
}